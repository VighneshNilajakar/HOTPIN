PS F:\Documents\HOTPIN> python main.py
INFO:     Started server process [7396]
INFO:     Waiting for application startup.

============================================================
ğŸš€ Hotpin Prototype Server Starting...
============================================================

ğŸ“¡ Network Information:
   WiFi Network: wifi
   IP Address: 10.184.66.58
   Interface: WiFi
   Server URL: http://10.184.66.58:8000
   WebSocket URL: ws://10.184.66.58:8000/ws

âœ“ Groq AsyncClient initialized with model: openai/gpt-oss-20b
Loading Vosk model from: ./model
LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2
LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 1 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 2 orphan components.
LOG (VoskAPI:Collapse():nnet-utils.cc:1488) Added 1 components, removed 2
LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from ./model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from ./model/graph/HCLr.fst ./model/graph/Gr.fst
LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo ./model/graph/phones/word_boundary.int
âœ“ Vosk model loaded successfully
   Model: ./model
   Format: 16000Hz, 1 channel, 16-bit
âœ“ pyttsx3 TTS engine test successful
============================================================
âœ“ Server ready at ws://0.0.0.0:8000/ws
============================================================

INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     10.184.66.214:53992 - "WebSocket /ws" [accepted]
ğŸ”Œ New WebSocket connection established
INFO:     connection open
âœ“ Session initialized: esp32-cam-hotpin
ğŸ¤ [esp32-cam-hotpin] End-of-speech signal received
ğŸ”„ [esp32-cam-hotpin] Processing 69632 bytes of audio...
âœ“ Transcription [esp32-cam-hotpin]: "you know"
ğŸ“ [esp32-cam-hotpin] Transcript: "you know"
ğŸ¤– [esp32-cam-hotpin] LLM response: "Could you clarify what you mean?"
âœ“ TTS synthesis completed: 80468 bytes generated
âœ“ Cleaned up temp file: C:\Users\VIGHNE~1\AppData\Local\Temp\hotpin_tts_6kiy3o44.wav
ğŸ”Š [esp32-cam-hotpin] Streaming 80468 bytes of audio response...
âœ“ [esp32-cam-hotpin] Response streaming complete
ğŸ”„ [esp32-cam-hotpin] Buffer reset, ready for next input
ğŸ“· [hotpin-998C64-28] Image received: image.jpg, 7993 bytes (7.81 KB)
ğŸ’¾ [hotpin-998C64-28] Image saved: captured_images/hotpin-998C64-28_20251018_233014.jpg
INFO:     10.184.66.214:53993 - "POST /image HTTP/1.1" 200 OK
ğŸ¤ [esp32-cam-hotpin] End-of-speech signal received
ğŸ”„ [esp32-cam-hotpin] Processing 132096 bytes of audio...
âœ“ Transcription [esp32-cam-hotpin]: "hello"
ğŸ“ [esp32-cam-hotpin] Transcript: "hello"
ğŸ¤– [esp32-cam-hotpin] LLM response: "Hello! How can I help you today?"
âœ“ TTS synthesis completed: 111568 bytes generated
âœ“ Cleaned up temp file: C:\Users\VIGHNE~1\AppData\Local\Temp\hotpin_tts_lj_ji24e.wav
ğŸ”Š [esp32-cam-hotpin] Streaming 111568 bytes of audio response...
âœ“ [esp32-cam-hotpin] Response streaming complete
ğŸ”„ [esp32-cam-hotpin] Buffer reset, ready for next input